{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b48b186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from decimal import *\n",
    "\n",
    "MAX_PRODUCT_LEN=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88b27ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://stackoverflow.com/questions/1960516/python-json-serialize-a-decimal-object\n",
    "class fakefloat(float):\n",
    "    def __init__(self, value):\n",
    "        self._value = value\n",
    "    def __repr__(self):\n",
    "        return str(self._value)\n",
    "    \n",
    "def defaultencode(o):\n",
    "    if isinstance(o, Decimal):\n",
    "        # Subclass float with custom repr?\n",
    "        return fakefloat(o)\n",
    "    raise TypeError(repr(o) + \" is not JSON serializable\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b823563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Address:\n",
    "    street = None\n",
    "    city = None\n",
    "    state = None\n",
    "    zipcode = None\n",
    "    \n",
    "    def __init__(self, street, city, state, zipcode):\n",
    "        self.street = street\n",
    "        self.city = city\n",
    "        self.state = state\n",
    "        self.zipcode = zipcode\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.street} {self.city} {self.state} {self.zipcode}'\n",
    "    \n",
    "    \n",
    "class Header:\n",
    "    address = None\n",
    "    cashier = None\n",
    "    phone = None\n",
    "    receipt_date = None\n",
    "    receipt_seqnum = None\n",
    "    \n",
    "    def __init__(self, address, cashier, phone, receipt_date, receipt_seqnum):\n",
    "        self.address = address\n",
    "        self.cashier = cashier\n",
    "        self.phone = phone\n",
    "        self.receipt_date = receipt_date\n",
    "        self.receipt_seqnum = receipt_seqnum\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'[address: {self.address}, cashier: {self.cashier}, phone: {self.phone}, \\n ' + \\\n",
    "               f'receipt_date: {self.receipt_date}, receipt_seqnum: {self.receipt_seqnum}]'\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "                'address': self.address.__dict__ if self.address else None,\n",
    "                'cashier': self.cashier,\n",
    "                'phone': self.phone,\n",
    "                'receipt_date': self.receipt_date,\n",
    "                'receipt_seqnum': self.receipt_seqnum\n",
    "               }\n",
    "\n",
    "\n",
    "class LineItem:\n",
    "    product = None\n",
    "    qty = None\n",
    "    unitprice = None\n",
    "    total = None\n",
    "    savings = None\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'LineItem(product={self.product}, qty={self.qty}, unitprice={self.unitprice}, total={self.total}, ' + \\\n",
    "            f'savings={self.savings})'\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return self.__dict__\n",
    "    \n",
    "    \n",
    "class Body:\n",
    "    line_items = None\n",
    "    tax = None\n",
    "    savings = None\n",
    "    balance = None\n",
    "    datetime = None\n",
    "    change = None\n",
    "    \n",
    "    def calc_balance(self):\n",
    "        sum = Decimal('0')\n",
    "        for item in self.line_items:\n",
    "            if item.total:\n",
    "                sum = sum + item.total \n",
    "        if self.tax:\n",
    "            sum += self.tax\n",
    "        return sum\n",
    "            \n",
    "    def calc_savings(self):\n",
    "        sum = Decimal('0')\n",
    "        for item in self.line_items:\n",
    "            if item.savings:\n",
    "                sum = sum + item.savings\n",
    "            if item.total is not None and item.total < 0:\n",
    "                if item.product != 'COUPON':\n",
    "                    # TODO I think coupons that are brought by the user are not counted towards savings\n",
    "                    # The other case that we're renaming as COUPON should be handled separately\n",
    "                    sum = sum + item.total * -1\n",
    "        return sum\n",
    "    \n",
    "    def calc_coupons(self):\n",
    "        sum = Decimal('0')\n",
    "        for item in self.line_items:\n",
    "            if item.product == 'COUPON':\n",
    "                sum = sum + item.total\n",
    "        return sum\n",
    "    \n",
    "    def __init__(self, line_items, tax, savings, balance, datetime, change):\n",
    "        self.line_items = line_items\n",
    "        if tax is not None:\n",
    "            self.tax = Decimal(str(tax))\n",
    "        if savings is not None:\n",
    "            self.savings = Decimal(str(savings))\n",
    "        if balance is not None:\n",
    "            self.balance = Decimal(str(balance))\n",
    "        self.datetime = datetime\n",
    "        if change is not None:\n",
    "            self.change = Decimal(str(change))\n",
    "        \n",
    "    def __str__(self):\n",
    "        return '----\\n' + \\\n",
    "            f'tax: {self.tax}\\n' + \\\n",
    "            f'savings: {self.savings}\\n' + \\\n",
    "            f'calculated_savings: {self.calc_savings()}\\n' + \\\n",
    "            f'balance: {self.balance}\\n' + \\\n",
    "            f'calculated_balance: {self.calc_balance()}\\n' + \\\n",
    "            f'coupon_total: {self.calc_coupons()}\\n' + \\\n",
    "            f'datetime: {self.datetime}\\n' + \\\n",
    "            f'change: {self.change}\\n' + \\\n",
    "            '\\n'.join([str(x) for x in self.line_items])\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'line_items': [item.to_dict() for item in self.line_items],\n",
    "            'tax': self.tax,\n",
    "            'savings': self.savings,\n",
    "            'calculated_savings': self.calc_savings(),\n",
    "            'balance': self.balance,\n",
    "            'calculated_balance': self.calc_balance(),\n",
    "            'coupon_total': self.calc_coupons(),\n",
    "            'change': self.change,\n",
    "            'datetime': self.datetime\n",
    "        }\n",
    "\n",
    "    \n",
    "class Receipt:\n",
    "    header = None\n",
    "    Body = None\n",
    "    \n",
    "    def __init__(self, header, body):\n",
    "        self.header = header\n",
    "        self.body = body\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str(self.header) + '\\n' + str(self.body)    \n",
    "    \n",
    "    def to_json(self):\n",
    "        return json.dumps({\n",
    "            'header': self.header.to_dict(),\n",
    "            'body': self.body.to_dict()\n",
    "        },\n",
    "        indent=4,\n",
    "        default=defaultencode)\n",
    "\n",
    "\n",
    "## Tokens    \n",
    "class ItemsAndQuantity:\n",
    "    qty = None\n",
    "    unitprice = None\n",
    "    \n",
    "    def __init__(self, qty, unitprice):\n",
    "        self.qty = float(qty)\n",
    "        self.unitprice = Decimal(unitprice)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'ItemsAndQuantity({self.qty}, {self.unitprice})'\n",
    "\n",
    "    \n",
    "class Product:\n",
    "    name = None\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'Product({self.name})'\n",
    "\n",
    "    \n",
    "class ItemTotal:\n",
    "    amount = None\n",
    "    \n",
    "    def __init__(self, amount):\n",
    "        self.amount = Decimal(amount)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'ItemTotal({self.amount})'\n",
    "\n",
    "    def to_json(self):\n",
    "        return json.dumps(self.__dict__)\n",
    "\n",
    "    \n",
    "class Savings:\n",
    "    amount = None\n",
    "    \n",
    "    def __init__(self, amount):\n",
    "        self.amount = Decimal(amount)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'Savings({self.amount})'\n",
    "    \n",
    "    def to_json(self):\n",
    "        return json.dumps(self.__dict__)\n",
    "    \n",
    "\n",
    "class Coupon:\n",
    "    amount = None\n",
    "    \n",
    "    def __init__(self, amount):\n",
    "        self.amount = Decimal(amount)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'Coupon({self.amount})'\n",
    "    \n",
    "    def to_json(self):\n",
    "        return json.dumps(self.__dict__)\n",
    "    \n",
    "\n",
    "class MegaEvent:\n",
    "    amount = None\n",
    "    \n",
    "    def __init__(self, amount):\n",
    "        self.amount = Decimal(amount)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'MegaEvent({self.amount})'\n",
    "    \n",
    "    def to_json(self):\n",
    "        return json.dumps(self.__dict__)\n",
    "    \n",
    "\n",
    "class GreenBagPts:\n",
    "    amount = None\n",
    "    \n",
    "    def __init__(self, amount):\n",
    "        self.amount = Decimal(amount)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'GreenBagPts({self.amount})'\n",
    "    \n",
    "    def to_json(self):\n",
    "        return json.dumps(self.__dict__)\n",
    "    \n",
    "\n",
    "class Noise:\n",
    "    noise = None\n",
    "    \n",
    "    def __init__(self, noise):\n",
    "        self.noise = noise\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'Noise({self.noise})'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84eda093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_items_and_quantity(text):\n",
    "    #'1.0 @ 10/10.00'\n",
    "    m = re.match('(\\d+\\.\\d+) @ (\\d+)/(\\d+\\.\\d+)', text)\n",
    "    if m:\n",
    "        qty = float(m[1])\n",
    "        unitprice = float(m[3]) / float(m[2])\n",
    "        return ItemsAndQuantity(qty, unitprice)\n",
    "    #'2.0 @ 0.1'\n",
    "    m = re.match('(\\d+) @ (\\d*\\.\\d+)', text)\n",
    "    if m:\n",
    "        return ItemsAndQuantity(m[1], m[2])\n",
    "    m = re.match('(\\d+\\.\\d+) @ (\\d*\\.\\d+)', text)\n",
    "    if m:\n",
    "        return ItemsAndQuantity(m[1], m[2])\n",
    "    m = re.match('(\\d+\\.\\d+) lb @ (\\d+\\.\\d+) /lb', text)\n",
    "    if m:\n",
    "        return ItemsAndQuantity(m[1], m[2])\n",
    "    return None\n",
    "\n",
    "def parse_item_total(text):\n",
    "    m = re.match('(\\d+\\.\\d+)-.', text)\n",
    "    if m:\n",
    "        d = Decimal(m[1])\n",
    "        d = d * -1\n",
    "        return ItemTotal(str(d))\n",
    "    m = re.match('(\\d+\\.\\d+)', text)\n",
    "    if m:\n",
    "        return ItemTotal(m[1])\n",
    "    return None\n",
    "\n",
    "def parse_savings_header(text):\n",
    "    m = re.match('RALPHS SAVED YOU', text)\n",
    "    if m:\n",
    "        return True   \n",
    "    m = re.match('.* (Sale)', text)\n",
    "    if m:\n",
    "        return True   \n",
    "    m = re.match('.*%\\s+off', text)\n",
    "    if m:\n",
    "        return True   \n",
    "    \n",
    "    return None\n",
    "\n",
    "def parse_savings_body(text):\n",
    "    m = re.match('(\\d+\\.\\d+)', text)\n",
    "    if m:\n",
    "        return Savings(m[1])\n",
    "    return None\n",
    "\n",
    "def parse_coupon_header(text):\n",
    "    m = re.match('SCANNED COUPON', text)\n",
    "    if m:\n",
    "        return True  \n",
    "    return None\n",
    "\n",
    "def parse_coupon_body(text):\n",
    "    m = re.match('(\\d+\\.\\d+)', text)\n",
    "    if m:\n",
    "        return Coupon(m[1])\n",
    "    return None\n",
    "\n",
    "def parse_megaevent_header(text):\n",
    "    m = re.match('Mega Event Savings', text)\n",
    "    if m:\n",
    "        return True\n",
    "    return None\n",
    "\n",
    "def parse_megaevent_body(text):\n",
    "    m = re.match('(\\d+\\.\\d+)', text)\n",
    "    if m:\n",
    "        return MegaEvent(m[1])\n",
    "    return None\n",
    "\n",
    "def parse_greenbagpts_header(text):\n",
    "    m = re.match('Green\\s+Bag\\s+Pts', text)\n",
    "    if m:\n",
    "        return True        \n",
    "    return None\n",
    "\n",
    "def parse_greenbagpts_body(text):\n",
    "    m = re.match('(\\d+)', text)\n",
    "    if m:\n",
    "        return GreenBagPts(m[1])\n",
    "    return None\n",
    "\n",
    "def parse_product(text):\n",
    "    if len(text) == MAX_PRODUCT_LEN and text.endswith('RC'):\n",
    "        text = text[:-2].strip()\n",
    "    return Product(text)\n",
    "\n",
    "def parse_noise(text):\n",
    "    m = re.match('(^SC$|^RC$|^WT$|^MC$|^NP$|^MR$|^DB$|^<\\+$|^.$)', text)\n",
    "    if m:\n",
    "        return Noise(m[1])\n",
    "    m = re.match('(^AGE$|^VERIFICATION BYPASSED$|AGE VERIFICATION BYPASSED)', text)\n",
    "    if m:\n",
    "        return Noise(m[1])\n",
    "    m = re.match('(^Age Restricted: 18$)', text)\n",
    "    if m:\n",
    "        return Noise(m[1])\n",
    "    return None\n",
    "\n",
    "def maybe_merge(text1, text2, text3):\n",
    "    '''\n",
    "    Return <increment>, <text>\n",
    "    where <increment> is the number of positions to advance, and <text> is the either <text1> or the merged text\n",
    "    '''\n",
    "    if text2 and text3:\n",
    "        # Example(from 2020_04_19_01): '1.0', '@', '10/10.00'\n",
    "        m1 = re.match('(\\d+\\.\\d+)', text1)\n",
    "        m2 = re.match('@', text2)\n",
    "        m3 = re.match('\\d+/\\d+\\.\\d+', text3)\n",
    "        if m1 and m2 and m3:\n",
    "            return 3, f'{text1} {text2} {text3}'\n",
    "        # Example(from 2020_04_19_01): '2', '@', '0.99'\n",
    "        m1 = re.match('\\d+', text1)\n",
    "        m2 = re.match('@', text2)\n",
    "        m3 = re.match('\\d+\\.\\d+', text3)\n",
    "        if m1 and m2 and m3:\n",
    "            return 3, f'{text1} {text2} {text3}'\n",
    "        \n",
    "    if text2:\n",
    "        m1 = re.match('(\\d\\.\\d+)', text1)\n",
    "        m2 = re.match('lb @ (\\d\\.\\d+) /lb', text2)\n",
    "        if m1 and m2:\n",
    "            return 2, f'{text1} {text2}'\n",
    "    return 1, text1\n",
    "\n",
    "def merge_text(texts):    \n",
    "    '''\n",
    "    In some cases, text might get split.  For example the item and quanity \"0.82 lb @ 0.99 /lb\"\n",
    "    can get split into \"0.82\" and \"lb @ 0.99 /lb\".\n",
    "    If we detect those patterns, merge them\n",
    "    '''\n",
    "    i = 0\n",
    "    result = []\n",
    "    merged = False\n",
    "    while i < len(texts):\n",
    "        text1 = texts[i]\n",
    "        text2 = texts[i+1] if i+1 < len(texts) else None\n",
    "        text3 = texts[i+2] if i+2 < len(texts) else None\n",
    "        increment, text = maybe_merge(text1, text2, text3)\n",
    "        result.append(text)\n",
    "        i += increment\n",
    "    return result        \n",
    "\n",
    "def parse_text(texts):\n",
    "    '''\n",
    "    Given a list of texts (strings) produce a list of tokens\n",
    "    '''\n",
    "    debug = False\n",
    "    tokens = []\n",
    "    i = -1\n",
    "    while i < len(texts) - 1:\n",
    "        i += 1\n",
    "        text = texts[i]\n",
    "        if debug:\n",
    "            print(f'parsing |{text}|')\n",
    "        token = parse_items_and_quantity(text)        \n",
    "        if token:\n",
    "            if debug:\n",
    "                print(token)\n",
    "            tokens.append(token)\n",
    "            continue\n",
    "        token = parse_noise(text)\n",
    "        if token:\n",
    "            if debug:\n",
    "                print(token)\n",
    "            continue\n",
    "        token = parse_savings_header(text)\n",
    "        if token:\n",
    "            if debug:\n",
    "                print(token)\n",
    "            i += 1\n",
    "            text = texts[i]\n",
    "            token = parse_savings_body(text)\n",
    "            if token:\n",
    "                tokens.append(token)\n",
    "                continue\n",
    "        token = parse_coupon_header(text)\n",
    "        if token:\n",
    "            if debug:\n",
    "                print(token)\n",
    "            i += 1\n",
    "            text = texts[i]\n",
    "            token = parse_coupon_body(text)\n",
    "            if token:\n",
    "                if debug:\n",
    "                    print(token)\n",
    "                tokens.append(token)\n",
    "                continue\n",
    "        token = parse_megaevent_header(text)\n",
    "        if token:\n",
    "            if debug:\n",
    "                print(token)\n",
    "            i += 1\n",
    "            text = texts[i]\n",
    "            token = parse_megaevent_body(text)\n",
    "            if token:\n",
    "                if debug:\n",
    "                    print(token)\n",
    "                tokens.append(token)\n",
    "                continue\n",
    "        token = parse_greenbagpts_header(text)\n",
    "        if token:\n",
    "            if debug:\n",
    "                print(token)\n",
    "            i += 1\n",
    "            text = texts[i]\n",
    "            token = parse_greenbagpts_body(text)\n",
    "            if token:\n",
    "                if debug:\n",
    "                    print(token)\n",
    "                tokens.append(token)\n",
    "                continue\n",
    "        token = parse_item_total(text)\n",
    "        if token:\n",
    "            if debug:\n",
    "                print(token)\n",
    "            tokens.append(token)\n",
    "            continue\n",
    "        token = parse_product(text)\n",
    "        if debug:\n",
    "            print(token)\n",
    "        tokens.append(token)\n",
    "    return tokens\n",
    "        \n",
    "\n",
    "def parse_tokens(tokens):\n",
    "    '''\n",
    "    Given a list of tokens produce a list of line items\n",
    "    '''\n",
    "    items = []\n",
    "    i = -1\n",
    "    item = None\n",
    "    while i < len(tokens) - 1:\n",
    "        i += 1\n",
    "        token = tokens[i]\n",
    "        if isinstance(token, ItemsAndQuantity):\n",
    "            item = LineItem()\n",
    "            item.qty = token.qty\n",
    "            item.unitprice = token.unitprice\n",
    "            #item.total = 0\n",
    "            items.append(item)\n",
    "            continue\n",
    "        if isinstance(token, Product):\n",
    "            if not item or item.total is not None:\n",
    "                item = LineItem()\n",
    "                #item.total = 0\n",
    "                items.append(item)\n",
    "            item.product = token.name\n",
    "            continue\n",
    "        if isinstance(token, ItemTotal):\n",
    "            item.total = token.amount\n",
    "            continue\n",
    "        if isinstance(token, Savings):\n",
    "            tempitem = item\n",
    "            if item.product == 'CA REDEM VAL':\n",
    "                tempitem = items[-2]\n",
    "            current_savings = tempitem.savings if tempitem.savings else 0\n",
    "            tempitem.savings = token.amount + current_savings\n",
    "        if isinstance(token, Coupon):\n",
    "            coupon = LineItem()\n",
    "            coupon.product = 'COUPON'\n",
    "            coupon.total = token.amount * -1\n",
    "            items.append(coupon)\n",
    "        if isinstance(token, MegaEvent):\n",
    "            mega = LineItem()\n",
    "            mega.product = 'MEGAEVENT'\n",
    "            mega.total = token.amount * -1\n",
    "            items.append(mega)\n",
    "    return items\n",
    "\n",
    "def filter_line_items(items):\n",
    "    return [i for i in items if not i.product.startswith('Trip Stakes')]\n",
    "        \n",
    "def find_and_extract(pattern, df):\n",
    "    '''\n",
    "    Find a pattern in df and extract the matching group.\n",
    "    Return the extracting and the (row, col) location. \n",
    "    If not found or not matched, return None\n",
    "    '''\n",
    "    for col in range(df.shape[1]):\n",
    "        df2 = df[df.columns[col]]\n",
    "        if df2.dtype != np.dtype('O'):\n",
    "            continue\n",
    "        df2 = df[df.columns[col]].str.findall(pattern).str.len() > 0\n",
    "        if not df2.any():\n",
    "            continue\n",
    "        row = df[df[df.columns[col]].str.findall(pattern).str.len() > 0].index[0]\n",
    "        contents = df.iloc[row, col]\n",
    "        m = re.match(pattern, contents)\n",
    "        if not m:\n",
    "            return None\n",
    "        if m.lastindex < 1:\n",
    "            return None\n",
    "        extracted = []\n",
    "        for i in range(1, m.lastindex + 1):\n",
    "            extracted.append(m[i])\n",
    "        return extracted, (row, col)\n",
    "    return None\n",
    "\n",
    "def extract_address(df):\n",
    "    '''\n",
    "    Return an address object\n",
    "    '''\n",
    "    city_state_zip_pattern = '(.*) (..) (\\d{5})'\n",
    "    street_pattern = '(\\d+ .* (Blvd|St|Way))'\n",
    "    street = None\n",
    "    city = None\n",
    "    state = None\n",
    "    zipcode = None\n",
    "    address = None\n",
    "    res = find_and_extract(street_pattern, df)\n",
    "    if res:\n",
    "        street = res[0][0]\n",
    "    res = find_and_extract(city_state_zip_pattern, df)\n",
    "    if res:\n",
    "        city_state_zip = res[0]\n",
    "        city = city_state_zip[0]\n",
    "        state = city_state_zip[1]\n",
    "        zipcode = city_state_zip[2]\n",
    "    if street or city or state or zipcode:\n",
    "        address = Address(street, city, state, zipcode)\n",
    "    return address\n",
    "    \n",
    "def extract_phone(df):\n",
    "    phone = None\n",
    "    res = find_and_extract('(\\(\\d{3}\\) \\d{3}-\\d{4})', df)\n",
    "    if res:\n",
    "        phone = res[0][0]\n",
    "    return phone\n",
    "\n",
    "def extract_cashier(df):\n",
    "    res = find_and_extract('Your cashier was (.*)', df)\n",
    "    rowcol = (0, 0)\n",
    "    cashier = None\n",
    "    if res:\n",
    "        cashier = res[0][0]\n",
    "        rowcol = res[1]    \n",
    "    return cashier, rowcol\n",
    "\n",
    "def extract_header(df, receipt_date, receipt_seqnum):\n",
    "    address = extract_address(df)\n",
    "    cashier, _ = extract_cashier(df)\n",
    "    phone = extract_phone(df)\n",
    "    header = Header(address, cashier, phone, receipt_date, receipt_seqnum)\n",
    "    return header\n",
    "    \n",
    "\n",
    "def find_rewards_customer_line(df):\n",
    "    res = find_and_extract('(RALPHS rewards CUSTOMER)', df)\n",
    "    if res:\n",
    "        line, rowcol = res\n",
    "        return rowcol[0]\n",
    "    res = find_and_extract('(rewards CUSTOMER)', df)\n",
    "    if res:\n",
    "        line, rowcol = res\n",
    "        return rowcol[0]\n",
    "    raise Exception('Cant find rewards customer line')\n",
    "\n",
    "\n",
    "def extract_line_item_text(df, start, end):\n",
    "    texts = []\n",
    "    for r in range(start, end):\n",
    "        for c in range(df.shape[1]):\n",
    "            text = df.iloc[r][c]\n",
    "            if len(str(text)) > 0 and str(text) != 'nan':\n",
    "                texts.append(str(text))\n",
    "    return texts\n",
    "\n",
    "def extract_line_items(df):\n",
    "    _, (row, _) = extract_cashier(df)\n",
    "    lineitem_start = row + 1\n",
    "    lineitem_end = find_rewards_customer_line(df)\n",
    "    texts = extract_line_item_text(df, lineitem_start, lineitem_end)\n",
    "    texts = merge_text(texts)\n",
    "    tokens = parse_text(texts)\n",
    "    items = parse_tokens(tokens)\n",
    "    return items\n",
    "\n",
    "def find_nonnull_column(df, row, start_col):\n",
    "    width = df.shape[1]\n",
    "    for col in range(start_col, width):\n",
    "        if not df.iloc[row:row+1, col:col+1].isnull().iloc[0,0]:\n",
    "            return col  \n",
    "        \n",
    "def extract_tax(df):\n",
    "    tax_res = find_and_extract('(TAX)',df)\n",
    "    if tax_res:\n",
    "        line, (row, col) = tax_res\n",
    "        tax = df.iloc[row][find_nonnull_column(df, row, col+1)]\n",
    "        return tax\n",
    "    return None\n",
    "    \n",
    "def extract_savings(df):\n",
    "    res = find_and_extract('(RALPHS rewards SAVINGS)',df)\n",
    "    if res:\n",
    "        line, (row, col) = res\n",
    "        savings = df.iloc[row][find_nonnull_column(df, row, col+1)]\n",
    "        return savings\n",
    "    return None\n",
    "    \n",
    "def extract_balance(df):\n",
    "    res = find_and_extract('.*(BALANCE)',df)\n",
    "    if res:\n",
    "        line, (row, col) = res\n",
    "        balance = df.iloc[row][find_nonnull_column(df, row, col+1)]\n",
    "        return balance\n",
    "    return None\n",
    "\n",
    "def extract_change(df):\n",
    "    res = find_and_extract('(CHANGE)',df)\n",
    "    if res:\n",
    "        line, (row, col) = res\n",
    "        change = df.iloc[row][find_nonnull_column(df, row, col+1)]\n",
    "        return change\n",
    "    return None\n",
    "\n",
    "def extract_datetime(df):\n",
    "    res = find_and_extract('(\\d{2})/(\\d{2})/(\\d{2}) (\\d{2}):(\\d{2})(.m)', df)\n",
    "    if res:\n",
    "        parts = res[0]\n",
    "        hour = parts[3]\n",
    "        if parts[-1] == 'pm':\n",
    "            hour = str(int(hour) + 12)\n",
    "        \n",
    "        datetime = f'20{parts[2]}-{parts[0]}-{parts[1]}T{hour}:{parts[4]}:00'\n",
    "        return datetime\n",
    "    return None\n",
    "    \n",
    "def extract_body(df):\n",
    "    line_items = extract_line_items(df)\n",
    "    line_items = filter_line_items(line_items)\n",
    "    tax = extract_tax(df)\n",
    "    savings = extract_savings(df)\n",
    "    balance = extract_balance(df)\n",
    "    datetime = extract_datetime(df)\n",
    "    change = extract_change(df)\n",
    "    body = Body(line_items, tax, savings, balance, datetime, change)\n",
    "    return body\n",
    "\n",
    "def validate_receipt(receipt):\n",
    "    assert receipt.body.balance\n",
    "    assert isinstance(receipt.body.balance, Decimal)\n",
    "    assert receipt.body.balance > 0\n",
    "    if receipt.body.savings:\n",
    "        assert receipt.body.savings == receipt.body.calc_savings()\n",
    "    assert receipt.body.balance == receipt.body.calc_balance()\n",
    "\n",
    "def extract_receipt(df, receipt_date, receipt_seqnum):\n",
    "    header = extract_header(df, receipt_date, receipt_seqnum)\n",
    "    body = extract_body(df)\n",
    "    receipt = Receipt(header, body)\n",
    "    return receipt\n",
    "\n",
    "def parse_receipt(excel_path, json_path, receipt_name, verbose=True, validate=True):\n",
    "    receipt_excel_path = f'{excel_path}/{receipt_name}.xlsx'\n",
    "    receipt_json_path = f'{json_path}/{receipt_name}.json'\n",
    "    df = pd.read_excel(receipt_excel_path)\n",
    "    receipt_date = receipt_name[:10]\n",
    "    receipt_seqnum = receipt_name[11:]\n",
    "    receipt = extract_receipt(df, receipt_date, receipt_seqnum)\n",
    "    if validate:\n",
    "        validate_receipt(receipt)\n",
    "    if verbose:\n",
    "        print(receipt)\n",
    "    f = open(receipt_json_path, \"w\")\n",
    "    j = receipt.to_json()\n",
    "    if verbose:\n",
    "        print(j)\n",
    "    f.write(j)\n",
    "    f.close()                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3abda1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For debugging\n",
    "\n",
    "def debug():\n",
    "    receipt_name = '2020_04_05_01'\n",
    "    receipt_excel_path = f'{excel_path}/{receipt_name}.xlsx'\n",
    "    df = pd.read_excel(receipt_excel_path)\n",
    "    texts = extract_line_item_text(df, 4, find_rewards_customer_line(df))\n",
    "    texts = merge_text(texts)\n",
    "    print(texts)\n",
    "    tokens = parse_text(texts)    \n",
    "    for t in tokens:\n",
    "        print(t)\n",
    "    return df, tokens\n",
    "        \n",
    "\n",
    "#df,tokens=debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96d11f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 2020_02_10_01....\n",
      "Parsing 2020_02_11_01....\n",
      "Parsing 2020_02_13_01....\n",
      "Parsing 2020_02_13_02....\n",
      "Parsing 2020_02_15_01....\n",
      "Parsing 2020_03_02_01....\n",
      "Parsing 2020_03_03_01....\n",
      "Parsing 2020_03_05_01....\n",
      "Parsing 2020_03_06_01....\n",
      "Parsing 2020_03_07_01....\n",
      "Parsing 2020_03_10_01....\n",
      "Parsing 2020_03_13_01....\n",
      "Parsing 2020_03_14_01....\n",
      "Parsing 2020_03_16_01....\n",
      "Parsing 2020_03_18_01....\n",
      "Parsing 2020_03_18_02....\n",
      "Parsing 2020_03_20_01....\n",
      "Parsing 2020_03_25_01....\n",
      "Parsing 2020_03_25_02....\n",
      "Parsing 2020_03_27_01....\n",
      "Parsing 2020_03_27_02....\n",
      "Parsing 2020_03_27_03....\n",
      "Parsing 2020_03_30_01....\n",
      "Parsing 2020_03_30_02....\n",
      "Parsing 2020_03_30_03....\n",
      "Parsing 2020_03_31_01....\n",
      "Parsing 2020_03_31_02....\n",
      "Parsing 2020_04_04_01....\n",
      "Parsing 2020_04_05_01....\n",
      "Parsing 2020_04_08_01....\n",
      "Parsing 2020_04_10_01....\n",
      "Parsing 2020_04_13_01....\n",
      "Parsing 2020_04_13_02....\n",
      "Parsing 2020_04_13_03....\n",
      "Parsing 2020_04_14_01....\n",
      "Parsing 2020_04_17_01....\n",
      "Parsing 2020_04_17_02....\n",
      "Parsing 2020_04_18_01....\n",
      "Parsing 2020_04_19_01....\n",
      "Parsing 2020_04_21_01....\n",
      "Parsing 2020_04_21_02....\n",
      "Parsing 2020_04_21_03....\n",
      "Parsing 2020_04_24_01....\n",
      "Parsing 2020_04_24_02....\n",
      "Parsing 2020_04_24_03....\n",
      "Parsing 2020_04_24_04....\n",
      "Parsing 2020_04_24_05....\n",
      "Parsing 2020_04_24_06....\n",
      "Parsing 2020_04_25_01....\n",
      "Parsing 2020_04_25_02....\n",
      "Parsing 2020_04_25_03....\n",
      "Parsing 2020_04_25_04....\n",
      "Parsing 2020_04_27_01....\n",
      "Parsing 2020_04_27_02....\n",
      "Parsing 2020_05_01_01....\n",
      "Parsing 2020_05_01_02....\n",
      "Parsing 2020_05_01_03....\n",
      "Parsing 2020_05_02_01....\n",
      "Parsing 2020_05_05_01....\n",
      "Parsing 2020_05_05_02....\n",
      "Parsing 2020_05_08_01....\n",
      "Parsing 2020_05_08_02....\n",
      "Parsing 2020_05_08_03....\n",
      "Parsing 2020_05_11_01....\n",
      "Parsing 2020_05_11_02....\n",
      "Parsing 2020_05_12_01....\n",
      "Parsing 2020_05_12_02....\n",
      "Parsing 2020_05_12_03....\n",
      "Parsing 2020_05_14_01....\n",
      "Parsing 2020_05_14_02....\n",
      "Parsing 2020_05_16_01....\n",
      "Parsing 2020_05_16_02....\n",
      "Parsing 2020_05_17_01....\n",
      "Parsing 2020_05_17_02....\n",
      "Parsing 2020_05_18_01....\n",
      "Parsing 2020_05_18_02....\n",
      "Parsing 2020_05_18_03....\n",
      "Parsing 2020_05_20_01....\n",
      "Parsing 2020_05_20_02....\n",
      "Parsing 2020_05_20_03....\n",
      "Parsing 2020_05_21_01....\n",
      "Parsing 2020_05_21_02....\n",
      "Parsing 2020_05_21_03....\n",
      "Parsing 2020_05_21_04....\n",
      "Parsing 2020_05_22_01....\n",
      "Parsing 2020_05_22_02....\n",
      "Parsing 2020_05_23_01....\n",
      "Parsing 2020_05_23_02....\n",
      "Parsing 2020_05_25_01....\n",
      "Parsing 2020_05_26_01....\n",
      "Parsing 2020_05_26_02....\n",
      "Parsing 2020_05_26_03....\n",
      "Parsing 2020_05_26_04....\n",
      "Parsing 2020_05_27_01....\n",
      "Parsing 2020_05_29_01....\n",
      "Parsing 2020_06_02_01....\n",
      "Parsing 2020_06_02_02....\n",
      "Parsing 2020_06_09_01....\n",
      "Parsing 2020_06_11_01....\n",
      "Parsing 2020_06_14_01....\n",
      "Parsing 2020_06_14_02....\n",
      "Parsing 2020_06_17_01....\n",
      "Parsing 2020_06_17_02....\n",
      "Parsing 2020_06_18_01....\n",
      "Parsing 2020_06_23_01....\n",
      "Parsing 2020_06_23_02....\n",
      "Parsing 2020_06_23_03....\n",
      "Parsing 2020_06_23_04....\n",
      "Parsing 2020_06_24_01....\n",
      "Parsing 2020_06_24_02....\n",
      "Parsing 2020_06_27_01....\n",
      "Parsing 2020_06_27_02....\n",
      "Parsing 2020_06_29_01....\n",
      "Parsing 2020_06_29_02....\n",
      "Parsing 2020_06_29_03....\n",
      "Parsing 2020_07_03_01....\n",
      "Parsing 2020_07_03_02....\n",
      "Parsing 2020_07_04_01....\n",
      "Parsing 2020_07_04_02....\n",
      "Parsing 2020_07_04_03....\n",
      "Parsing 2020_07_08_01....\n",
      "Parsing 2020_07_08_02....\n",
      "Parsing 2020_07_12_01....\n",
      "Parsing 2020_07_12_02....\n",
      "Parsing 2020_07_13_01....\n",
      "Parsing 2020_07_13_02....\n",
      "Parsing 2020_07_13_03....\n",
      "Parsing 2020_07_13_04....\n",
      "Parsing 2020_07_15_01....\n",
      "Parsing 2020_07_17_01....\n",
      "Parsing 2020_07_17_02....\n",
      "Parsing 2020_07_17_03....\n",
      "Parsing 2020_07_22_01....\n",
      "Parsing 2020_07_23_01....\n",
      "Parsing 2020_07_23_02....\n",
      "Parsing 2020_07_23_03....\n",
      "Parsing 2020_07_23_04....\n",
      "Parsing 2020_07_24_01....\n",
      "Parsing 2020_07_24_02....\n",
      "Parsing 2020_07_25_01....\n",
      "Parsing 2020_07_25_02....\n",
      "Parsing 2020_07_28_01....\n",
      "Parsing 2020_07_28_02....\n",
      "Parsing 2020_07_31_01....\n",
      "Parsing 2020_07_31_02....\n",
      "Parsing 2020_08_04_01....\n",
      "Parsing 2020_08_04_02....\n",
      "Parsing 2020_08_04_03....\n",
      "Parsing 2020_08_04_04....\n",
      "Parsing 2020_08_04_05....\n",
      "Parsing 2020_08_04_06....\n",
      "Parsing 2020_08_06_01....\n",
      "Parsing 2020_08_06_02....\n",
      "Parsing 2020_08_06_03....\n",
      "Parsing 2020_08_06_04....\n",
      "Parsing 2020_08_07_01....\n",
      "Parsing 2020_08_08_01....\n",
      "Parsing 2020_08_08_02....\n",
      "Parsing 2020_08_10_01....\n",
      "Parsing 2020_08_12_01....\n",
      "Parsing 2020_08_12_02....\n",
      "Parsing 2020_08_15_01....\n",
      "Parsing 2020_08_15_02....\n",
      "Parsing 2020_08_17_01....\n",
      "Parsing 2020_08_17_02....\n",
      "Parsing 2020_08_19_01....\n",
      "Parsing 2020_08_19_02....\n",
      "Parsing 2020_08_19_03....\n",
      "Parsing 2020_08_21_01....\n",
      "Parsing 2020_08_21_02....\n",
      "Parsing 2020_08_26_01....\n",
      "Parsing 2020_08_26_02....\n",
      "Parsing 2020_08_27_01....\n",
      "Parsing 2020_08_28_01....\n",
      "Parsing 2020_08_28_02....\n",
      "Parsing 2020_09_02_01....\n",
      "Parsing 2020_09_02_02....\n",
      "Parsing 2020_09_08_01....\n",
      "Parsing 2020_09_11_01....\n",
      "Parsing 2020_09_11_02....\n",
      "Parsing 2020_09_13_01....\n",
      "Parsing 2020_09_13_02....\n",
      "Parsing 2020_09_14_01....\n",
      "Parsing 2020_09_14_02....\n",
      "Parsing 2020_09_15_01....\n",
      "Parsing 2020_09_15_02....\n",
      "Parsing 2020_09_17_01....\n",
      "Parsing 2020_09_17_02....\n",
      "Parsing 2020_09_19_01....\n",
      "Parsing 2020_09_19_02....\n",
      "Parsing 2020_09_21_01....\n",
      "Parsing 2020_09_26_01....\n",
      "Parsing 2020_10_01_01....\n",
      "Parsing 2020_10_06_01....\n",
      "Parsing 2020_10_07_01....\n",
      "Parsing 2020_10_07_02....\n",
      "Parsing 2020_10_08_01....\n",
      "Parsing 2020_10_08_02....\n",
      "Parsing 2020_10_12_01....\n",
      "Parsing 2020_10_12_02....\n",
      "Parsing 2020_10_12_03....\n",
      "Parsing 2020_10_14_01....\n",
      "Parsing 2020_10_19_01....\n",
      "Parsing 2020_10_19_02....\n",
      "Parsing 2020_10_21_01....\n",
      "Parsing 2020_10_21_02....\n",
      "Parsing 2020_10_24_01....\n",
      "Parsing 2020_10_24_02....\n",
      "Parsing 2020_10_31_01....\n",
      "Parsing 2020_11_03_01....\n",
      "Parsing 2020_11_03_02....\n",
      "Parsing 2020_11_10_01....\n",
      "Parsing 2020_11_12_01....\n",
      "Parsing 2020_11_16_01....\n",
      "Parsing 2020_11_18_01....\n",
      "Parsing 2020_11_18_02....\n",
      "Parsing 2020_11_21_01....\n",
      "Parsing 2020_11_22_01....\n",
      "Parsing 2020_11_23_01....\n",
      "Parsing 2020_11_23_02....\n",
      "Parsing 2020_11_24_01....\n",
      "Parsing 2020_11_24_02....\n",
      "Parsing 2020_11_24_03....\n",
      "Parsing 2020_11_25_01....\n",
      "Parsing 2020_11_25_02....\n",
      "Parsing 2020_11_26_01....\n",
      "Parsing 2020_11_30_01....\n",
      "Parsing 2020_11_30_02....\n",
      "Parsing 2020_12_17_01....\n",
      "Parsing 2020_12_17_02....\n",
      "Parsing 2020_12_20_01....\n",
      "Parsing 2020_12_20_02....\n",
      "Parsing 2020_12_24_01....\n",
      "Parsing 2020_12_26_01....\n",
      "Parsing 2020_12_28_01....\n",
      "Parsing 2020_12_31_01....\n",
      "Parsing 2021_01_02_01....\n",
      "Parsing 2021_01_03_01....\n",
      "Parsing 2021_01_03_02....\n",
      "Parsing 2021_01_11_01....\n",
      "Parsing 2021_01_11_02....\n",
      "Parsing 2021_01_11_03....\n",
      "Parsing 2021_01_18_01....\n",
      "Parsing 2021_01_18_02....\n",
      "Parsing 2021_01_19_01....\n",
      "Parsing 2021_01_20_01....\n",
      "Parsing 2021_01_20_02....\n",
      "Parsing 2021_01_22_01....\n",
      "Parsing 2021_01_22_02....\n",
      "Parsing 2021_01_22_03....\n",
      "Parsing 2021_01_28_01....\n",
      "Parsing 2021_01_30_01....\n",
      "Parsing 2021_02_06_01....\n",
      "Parsing 2021_02_14_01....\n",
      "Parsing 2021_02_14_02....\n",
      "Parsing 2021_02_15_01....\n",
      "Parsing 2021_02_16_01....\n",
      "Parsing 2021_02_18_01....\n",
      "Parsing 2021_02_18_02....\n",
      "Parsing 2021_02_19_01....\n",
      "Parsing 2021_02_21_01....\n",
      "Parsing 2021_02_21_02....\n",
      "Parsing 2021_02_24_01....\n",
      "Parsing 2021_02_28_01....\n",
      "Parsing 2021_03_01_01....\n",
      "Parsing 2021_03_03_01....\n",
      "Parsing 2021_03_04_01....\n",
      "Parsing 2021_03_07_01....\n",
      "Parsing 2021_03_07_02....\n",
      "Parsing 2021_03_08_01....\n",
      "Parsing 2021_03_09_01....\n",
      "Parsing 2021_03_11_01....\n",
      "Parsing 2021_03_13_01....\n",
      "Parsing 2021_03_13_02....\n",
      "Parsing 2021_03_13_03....\n",
      "Parsing 2021_03_14_01....\n",
      "Parsing 2021_03_14_02....\n",
      "Parsing 2021_03_15_01....\n",
      "Parsing 2021_03_17_01....\n",
      "Parsing 2021_03_23_01....\n",
      "Parsing 2021_03_24_01....\n",
      "Parsing 2021_03_24_02....\n",
      "Parsing 2021_03_24_03....\n",
      "Parsing 2021_03_26_01....\n",
      "Parsing 2021_03_29_01....\n",
      "Parsing 2021_04_03_01....\n",
      "Parsing 2021_04_05_01....\n",
      "Parsing 2021_04_12_01....\n",
      "Parsing 2021_04_12_02....\n",
      "Parsing 2021_04_16_01....\n",
      "Parsing 2021_04_16_02....\n",
      "Parsing 2021_04_16_03....\n",
      "Parsing 2021_04_17_01....\n",
      "Parsing 2021_04_19_01....\n",
      "Parsing 2021_04_23_01....\n",
      "Parsing 2021_04_26_01....\n",
      "Parsing 2021_05_01_01....\n",
      "Parsing 2021_05_11_01....\n",
      "Parsing 2021_05_19_01....\n",
      "Parsing 2021_05_31_01....\n",
      "Parsing 2021_06_01_01....\n",
      "Parsing 2021_06_04_01....\n",
      "Parsing 2021_06_06_01....\n",
      "Parsing 2021_06_07_01....\n",
      "Parsing 2021_06_12_01....\n",
      "Parsing 2021_06_21_01....\n",
      "Parsing 2021_06_25_01....\n",
      "Parsing 2021_06_28_01....\n",
      "Parsing 2021_07_01_01....\n",
      "Parsing 2021_07_04_01....\n",
      "Parsing 2021_07_05_01....\n",
      "Parsing 2021_07_09_01....\n",
      "Parsing 2021_07_13_01....\n",
      "Parsing 2021_07_17_01....\n",
      "Parsing 2021_07_20_01....\n",
      "Parsing 2021_07_27_01....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 2021_08_02_01....\n",
      "Parsing 2021_08_10_01....\n"
     ]
    }
   ],
   "source": [
    "chunk = 0\n",
    "chunksize = 500\n",
    "validate=True\n",
    "#validate=False\n",
    "problem_receipts = [\n",
    "#    '2020_04_19_01',\n",
    "                   ]\n",
    "\n",
    "base_path = '/Users/ericmelz/Desktop/Ralphs/Receipts'\n",
    "excel_path = f'{base_path}/Excel'\n",
    "json_path = f'{base_path}/JSON'\n",
    "\n",
    "l = os.listdir(excel_path)\n",
    "all_receipt_names = sorted([f.split('.')[0] for f in l])\n",
    "\n",
    "start_offset = chunksize * chunk\n",
    "end_offset = start_offset + chunksize\n",
    "receipt_names = all_receipt_names[start_offset:end_offset]\n",
    "\n",
    "for receipt_name in receipt_names:\n",
    "    print(f'Parsing {receipt_name}....', end='')\n",
    "    if receipt_name in problem_receipts:\n",
    "        print('SKIPPING!')\n",
    "        continue\n",
    "    print()\n",
    "    parse_receipt(excel_path, json_path, receipt_name, verbose=False, validate=validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e5352",
   "metadata": {},
   "source": [
    "# TODO\n",
    "Import models.py, eliminate existing business classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ed6659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
